{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data size before dropping Id feature is : (1460, 81) \n",
      "The test data size before dropping Id feature is : (1459, 80) \n",
      "\n",
      "The train data size after dropping Id feature is : (1460, 80) \n",
      "The test data size after dropping Id feature is : (1459, 79) \n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#check the numbers of samples and features\n",
    "print(\"The train data size before dropping Id feature is : {} \".format(train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40% cutoff point\n",
    "cutoff = len(data) * 2 // 5\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = []\n",
    "for col in data.columns.values:\n",
    "    if data[col].isna().sum() > cutoff:\n",
    "        data.drop(col, axis=1, inplace=True)\n",
    "        features_drop.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features drop: ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n"
     ]
    }
   ],
   "source": [
    "print(\"features drop:\", features_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = []\n",
    "categoric = []\n",
    "for col in labels:\n",
    "    if data[col].dtype == 'object':\n",
    "        categoric.append(col)\n",
    "    else:\n",
    "        numeric.append(col)\n",
    "numeric.remove('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move outliers to other dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[numeric].copy()\n",
    "mean_ = temp.mean(axis=0)\n",
    "std_ = temp.std(axis=0)\n",
    "temp = (temp.sub(mean_, axis=1)).div(std_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteria: nromalize data and pick the ones that are mroe than 3 std away from mean\n",
    "dataOut = pd.DataFrame(columns=labels)\n",
    "for i in temp.index.values:\n",
    "    for col in temp.columns.values:\n",
    "        if abs(temp.loc[i, col]) > 3:\n",
    "            dataOut = dataOut.append(data.loc[i])\n",
    "            data.drop(i, inplace=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform categorical features in dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal\n",
    "data = data.reindex(sorted(data.columns), axis=1)\n",
    "for category in categoric:\n",
    "    series = data[category]\n",
    "    dummies = pd.get_dummies(series, prefix=category)\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "data.drop(categoric, axis=1, inplace=True)\n",
    "\n",
    "# outlier\n",
    "dataOut = dataOut.reindex(sorted(dataOut.columns), axis=1)\n",
    "for category in categoric:\n",
    "    series = dataOut[category]\n",
    "    dummies = pd.get_dummies(series, prefix=category)\n",
    "    dataOut = pd.concat([dataOut, dummies], axis=1)\n",
    "dataOut.drop(categoric, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill na in numeric categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal\n",
    "for num in numeric:\n",
    "    if data[num].isna().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        data[num].fillna(data[num].median(), inplace=True)\n",
    "        \n",
    "# Outlier\n",
    "for num in numeric:\n",
    "    if dataOut[num].isna().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        dataOut[num].fillna(dataOut[num].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "Xout = dataOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.copy()\n",
    "test_data.drop(features_drop, axis=1, inplace=True)\n",
    "test_data = test_data.reindex(sorted(test_data.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_data[numeric].copy()\n",
    "tempTest = (temp.sub(mean_, axis=1)).div(std_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.drop('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOut = pd.DataFrame(columns=labels)\n",
    "for i in tempTest.index.values:\n",
    "    for col in tempTest.columns.values:\n",
    "        if abs(tempTest.loc[i, col]) > 4:\n",
    "            testOut = testOut.append(test_data.loc[i])\n",
    "            test_data.drop(i, inplace=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal\n",
    "for category in categoric:\n",
    "    series = test_data[category]\n",
    "    dummies = pd.get_dummies(series, prefix=category)\n",
    "    test_data = pd.concat([test_data, dummies], axis=1)\n",
    "    \n",
    "# Outliers\n",
    "for category in categoric:\n",
    "    series = testOut[category]\n",
    "    dummies = pd.get_dummies(series, prefix=category)\n",
    "    testOut = pd.concat([testOut, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in numeric:\n",
    "    if test_data[num].isna().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        test_data[num].fillna(test_data[num].median(), inplace=True)\n",
    "        \n",
    "for num in numeric:\n",
    "    if testOut[num].isna().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        testOut[num].fillna(testOut[num].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['SalePrice']\n",
    "yOut = dataOut['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(categoric, axis=1, inplace=True)\n",
    "testOut.drop(categoric, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_features = test_data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = ['Condition2_Artery', 'Condition2_PosA', 'Condition2_PosN', 'RoofStyle_Shed',\n",
    "           'ExterCond_Ex', 'ExterCond_Po', 'HeatingQC_Po', 'GarageType_2Types']\n",
    "for f in dropped:\n",
    "    true_features.remove(f)\n",
    "    \n",
    "X = X[true_features]\n",
    "test_data.drop(dropped, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_features_out = testOut.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = ['LotConfig_FR3', 'Exterior2nd_CBlock']\n",
    "\n",
    "for f in dropped:\n",
    "    true_features_out.remove(f)\n",
    "    \n",
    "Xout = Xout[true_features_out]\n",
    "testOut.drop(dropped, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = test_data\n",
    "XtestOut = testOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OutInd = XtestOut.index\n",
    "NormInd = Xtest.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for trees 250 is: 0.8875065929802199\n",
      "score for trees 300 is: 0.8877090180717583\n",
      "score for trees 350 is: 0.8872412886610966\n",
      "score for trees 400 is: 0.8868678944179371\n",
      "score for trees 450 is: 0.8886270967033363\n",
      "score for trees 500 is: 0.8889393915681604\n"
     ]
    }
   ],
   "source": [
    "best_trees = 0\n",
    "score = 0\n",
    "for i in [250, 300, 350, 400, 450, 500]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = i, max_depth = 3, min_samples_split = 2,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for trees \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_trees = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for depth 2 is: 0.8918914337090351\n",
      "score for depth 3 is: 0.8882955361645992\n",
      "score for depth 4 is: 0.8913518790072203\n",
      "score for depth 5 is: 0.8880782642958602\n",
      "score for depth 6 is: 0.8820401490579778\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "score = 0\n",
    "for i in [2, 3, 4, 5, 6]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = i, min_samples_split = 2,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for depth \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_depth = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for min sample split 2 is: 0.8918049122829474\n",
      "score for min sample split 3 is: 0.8913629951084051\n",
      "score for min sample split 4 is: 0.888311996396773\n",
      "score for min sample split 5 is: 0.8904064226957366\n",
      "score for min sample split 6 is: 0.890855821000386\n",
      "score for min sample split 7 is: 0.8896438336254056\n"
     ]
    }
   ],
   "source": [
    "best_sample_split = 0\n",
    "score = 0\n",
    "for i in [2, 3, 4, 5, 6, 7]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = best_depth, min_samples_split = i,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for min sample split \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_sample_split = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators: 500\n",
      "Best depth: 2\n",
      "Best min sample split: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Best number of estimators:\", best_trees)\n",
    "print(\"Best depth:\", best_depth)\n",
    "print(\"Best min sample split:\", best_sample_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = best_depth, \n",
    "                                         min_samples_split = best_sample_split,\n",
    "                                         learning_rate = 0.1, loss = 'ls')\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(Xtest)\n",
    "y_predS = pd.Series(y_pred, index=NormInd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9101807859142227"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcv = linear_model.LassoCV(alphas=\n",
    "                           (27,28,29,30,31,32,33,35), cv=5, max_iter=15000, normalize = True)\n",
    "lcv.fit(X_train, y_train)\n",
    "print (\"Alpha Value: \", (lcv.alpha_))\n",
    "lcv.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9063779589096186"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv = linear_model.RidgeCV(alphas=(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n",
    "                           cv=5)\n",
    "rcv.fit(X_train, y_train)\n",
    "print (\"Alpha Value: \", (rcv.alpha_))\n",
    "rcv.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  19\n"
     ]
    }
   ],
   "source": [
    "lcv = linear_model.LassoCV(alphas=(14,18,19,21,22,20,25,27,28,29,30,31,32,33),\n",
    "                           cv=5,normalize = True)\n",
    "lcv.fit(X, y)\n",
    "print (\"Alpha Value: \", (lcv.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predR = lcv.predict(Xtest)\n",
    "y_predRS = pd.Series(y_predR, index=NormInd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(Xout, yOut, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for trees 250 is: 0.9095468247227835\n",
      "score for trees 300 is: 0.9195711969288526\n",
      "score for trees 350 is: 0.9187735038875045\n",
      "score for trees 400 is: 0.9038613843456837\n",
      "score for trees 450 is: 0.9218866928812638\n",
      "score for trees 500 is: 0.9170296732617242\n"
     ]
    }
   ],
   "source": [
    "best_trees = 0\n",
    "score = 0\n",
    "for i in [250, 300, 350, 400, 450, 500]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = i, max_depth = 3, min_samples_split = 2,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for trees \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_trees = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for depth 2 is: 0.9092072719327745\n",
      "score for depth 3 is: 0.9203562279339116\n",
      "score for depth 4 is: 0.9073840654182316\n",
      "score for depth 5 is: 0.9046124696555673\n",
      "score for depth 6 is: 0.8964740007494987\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "score = 0\n",
    "for i in [2, 3, 4, 5, 6]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = i, min_samples_split = 2,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for depth \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_depth = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for min sample split 2 is: 0.9148792513798673\n",
      "score for min sample split 3 is: 0.9262278296276024\n",
      "score for min sample split 4 is: 0.9285791267934222\n",
      "score for min sample split 5 is: 0.9252843296215632\n",
      "score for min sample split 6 is: 0.9267992064246494\n",
      "score for min sample split 7 is: 0.9181407047931781\n"
     ]
    }
   ],
   "source": [
    "best_sample_split = 0\n",
    "score = 0\n",
    "for i in [2, 3, 4, 5, 6, 7]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = best_depth, min_samples_split = i,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for min sample split \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_sample_split = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators: 450\n",
      "Best depth: 3\n",
      "Best min sample split: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Best number of estimators:\", best_trees)\n",
    "print(\"Best depth:\", best_depth)\n",
    "print(\"Best min sample split:\", best_sample_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=450, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = best_depth, \n",
    "                                         min_samples_split = best_sample_split,\n",
    "                                         learning_rate = 0.1, loss = 'ls')\n",
    "clf.fit(Xout, yOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_out = clf.predict(XtestOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_outS = pd.Series(y_pred_out, index=OutInd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7835499037788914"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcv = linear_model.LassoCV(alphas=\n",
    "                           (10,11,12,13,14,15,16,), cv=5, max_iter=15000, normalize = True)\n",
    "lcv.fit(X_train, y_train)\n",
    "print (\"Alpha Value: \", (lcv.alpha_))\n",
    "lcv.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7861113953864316"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv = linear_model.RidgeCV(alphas=(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n",
    "                           cv=5)\n",
    "rcv.fit(X_train, y_train)\n",
    "print (\"Alpha Value: \", (rcv.alpha_))\n",
    "rcv.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  10\n"
     ]
    }
   ],
   "source": [
    "rcv = linear_model.RidgeCV(alphas=(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n",
    "                           cv=5)\n",
    "rcv.fit(Xout, yOut)\n",
    "print (\"Alpha Value: \", (rcv.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predR_out = rcv.predict(XtestOut)\n",
    "y_predR_outS = pd.Series(y_predR_out, index=OutInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredCombOut = y_pred_outS # * 1/2 + 1/2 * y_predR_outS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredComb = 1/2 * y_predS + 1/2 * y_predRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = yPredComb.append(yPredCombOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = yPred\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
