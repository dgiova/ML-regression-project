{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data size before dropping Id feature is : (2051, 81) \n",
      "The test data size before dropping Id feature is : (879, 80) \n",
      "\n",
      "The train data size after dropping Id feature is : (2051, 80) \n",
      "The test data size after dropping Id feature is : (879, 79) \n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#check the numbers of samples and features\n",
    "print(\"The train data size before dropping Id feature is : {} \".format(train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = train['ID']\n",
    "test_ID = test['ID']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(\"ID\", axis = 1, inplace = True)\n",
    "test.drop(\"ID\", axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDum = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40% cutoff point\n",
    "cutoff = len(dataDum) * 2 // 5\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = []\n",
    "features_filled_std = {}\n",
    "for col in dataDum.columns.values:\n",
    "    if dataDum[col].isna().sum() > cutoff:\n",
    "        dataDum.drop(col, axis=1, inplace=True)\n",
    "        features_drop.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features drop: ['FenceQuality', 'Misc Feature', 'FireplaceQuality', 'PoolQuality', 'TypeOfAlleyAccess']\n"
     ]
    }
   ],
   "source": [
    "print(\"features drop:\", features_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataDum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = []\n",
    "categoric = []\n",
    "for col in labels:\n",
    "    if dataDum[col].dtype == 'object':\n",
    "        categoric.append(col)\n",
    "    else:\n",
    "        numeric.append(col)\n",
    "numeric.remove('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move outliers to other dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dataDum[numeric].copy()\n",
    "mean_ = temp.mean(axis=0)\n",
    "std_ = temp.std(axis=0)\n",
    "temp = (temp.sub(mean_, axis=1)).div(std_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOut = pd.DataFrame(columns=labels)\n",
    "for i in temp.index.values:\n",
    "    for col in temp.columns.values:\n",
    "        if abs(temp.loc[i, col]) > 3:\n",
    "            dataOut = dataOut.append(dataDum.loc[i])\n",
    "            dataDum.drop(i, inplace=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform categorical features in dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal\n",
    "dataDum = dataDum.reindex(sorted(dataDum.columns), axis=1)\n",
    "for category in categoric:\n",
    "    series = dataDum[category]\n",
    "    dummies = pd.get_dummies(series, prefix=category)\n",
    "    dataDum = pd.concat([dataDum, dummies], axis=1)\n",
    "dataDum.drop(categoric, axis=1, inplace=True)\n",
    "\n",
    "# outlier\n",
    "dataOut = dataOut.reindex(sorted(dataOut.columns), axis=1)\n",
    "for category in categoric:\n",
    "    series = dataOut[category]\n",
    "    dummies = pd.get_dummies(series, prefix=category)\n",
    "    dataOut = pd.concat([dataOut, dummies], axis=1)\n",
    "dataOut.drop(categoric, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill na in numeric categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal\n",
    "for num in numeric:\n",
    "    if dataDum[num].isna().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        dataDum[num].fillna(dataDum[num].median(), inplace=True)\n",
    "        \n",
    "# Outlier\n",
    "for num in numeric:\n",
    "    if dataOut[num].isna().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        dataOut[num].fillna(dataOut[num].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1451 entries, 1 to 2050\n",
      "Columns: 258 entries, 1stFloorArea to GarageType_Detchd\n",
      "dtypes: float64(11), int64(26), uint8(221)\n",
      "memory usage: 743.9 KB\n"
     ]
    }
   ],
   "source": [
    "# check dataset\n",
    "dataDum.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 600 entries, 0 to 2048\n",
      "Columns: 266 entries, 1stFloorArea to GarageType_Detchd\n",
      "dtypes: float64(11), object(26), uint8(229)\n",
      "memory usage: 312.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataOut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataDum\n",
    "Xout = dataOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDum = test.copy()\n",
    "testDum.drop(features_drop, axis=1, inplace=True)\n",
    "testDum = testDum.reindex(sorted(testDum.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = testDum[numeric].copy()\n",
    "tempTest = (temp.sub(mean_, axis=1)).div(std_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.drop('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOut = pd.DataFrame(columns=labels)\n",
    "for i in tempTest.index.values:\n",
    "    for col in tempTest.columns.values:\n",
    "        if abs(tempTest.loc[i, col]) > 4:\n",
    "            testOut = testOut.append(testDum.loc[i])\n",
    "            testDum.drop(i, inplace=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal\n",
    "for category in categoric:\n",
    "    series = testDum[category]\n",
    "    dummies = pd.get_dummies(series, prefix=category)\n",
    "    testDum = pd.concat([testDum, dummies], axis=1)\n",
    "    \n",
    "# Outliers\n",
    "for category in categoric:\n",
    "    series = testOut[category]\n",
    "    dummies = pd.get_dummies(series, prefix=category)\n",
    "    testOut = pd.concat([testOut, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in numeric:\n",
    "    if testDum[num].isna().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        testDum[num].fillna(testDum[num].median(), inplace=True)\n",
    "        \n",
    "for num in numeric:\n",
    "    if testOut[num].isna().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        testOut[num].fillna(testOut[num].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataDum['SalePrice']\n",
    "yOut = dataOut['SalePrice']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# testDum.drop(dropped_corr, axis=1, inplace=True)\n",
    "temp = dataDum[numeric]\n",
    "std_devs = temp.std(axis=0)\n",
    "means = temp.mean(axis=0)\n",
    "norm = (testDum[numeric].sub(means,axis=1)).div(std_devs, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "outlie = []\n",
    "for col in norm.columns.values:\n",
    "    if sum(norm[col] > 7) > 2:\n",
    "        outlie.append(col)\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "testDum.drop(outlie, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDum.drop(categoric, axis=1, inplace=True)\n",
    "testOut.drop(categoric, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_features = testDum.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = ['KitchenQuality_Po', 'Neighborhood_Landmrk', 'Exterior1_PreCast', 'Exterior2_PreCast',\n",
    "           'Exterior2_Stone',\n",
    "           'ProximityToMainRoad2_PosN', 'HeatingQuality_Po', 'HeatingType_Wall']\n",
    "for f in dropped:\n",
    "    true_features.remove(f)\n",
    "    \n",
    "X = X[true_features]\n",
    "testDum.drop(dropped, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_features_out = testOut.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = ['ProximityToMainRoad2_Artery', 'ProximityToMainRoad2_PosA',\n",
    "           'ProximityToMainRoad2_RRAe', 'SaleType_Con', 'SaleType_VWD',\n",
    "           'RoofMaterial_Roll', 'Foundation_Wood', 'HouseStyle_1.5Unf',\n",
    "           'Functional_Sal', 'ExteriorCond_Po', 'GarageQuality_Po', 'Exterior2_CBlock']\n",
    "\n",
    "for f in dropped:\n",
    "    true_features_out.remove(f)\n",
    "    \n",
    "Xout = Xout[true_features_out]\n",
    "testOut.drop(dropped, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = testDum\n",
    "XtestOut = testOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OutInd = XtestOut.index\n",
    "NormInd = Xtest.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for trees 250 is: 0.9316952001726577\n",
      "score for trees 300 is: 0.9320355860355257\n",
      "score for trees 350 is: 0.9332977650969084\n",
      "score for trees 400 is: 0.932439864478728\n",
      "score for trees 450 is: 0.9321421667950491\n",
      "score for trees 500 is: 0.9323002339052194\n"
     ]
    }
   ],
   "source": [
    "best_trees = 0\n",
    "score = 0\n",
    "for i in [250, 300, 350, 400, 450, 500]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = i, max_depth = 3, min_samples_split = 2,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for trees \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_trees = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for depth 2 is: 0.92706857100626\n",
      "score for depth 3 is: 0.9326548749815072\n",
      "score for depth 4 is: 0.9188135548680502\n",
      "score for depth 5 is: 0.9208962466849677\n",
      "score for depth 6 is: 0.9176621483289653\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "score = 0\n",
    "for i in [2, 3, 4, 5, 6]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = i, min_samples_split = 2,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for depth \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_depth = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for min sample split 2 is: 0.9326637377662864\n",
      "score for min sample split 3 is: 0.9316223264370375\n",
      "score for min sample split 4 is: 0.9304996279509723\n",
      "score for min sample split 5 is: 0.9296725380151528\n",
      "score for min sample split 6 is: 0.930580156621935\n",
      "score for min sample split 7 is: 0.9309016468283435\n"
     ]
    }
   ],
   "source": [
    "best_sample_split = 0\n",
    "score = 0\n",
    "for i in [2, 3, 4, 5, 6, 7]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = best_depth, min_samples_split = i,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for min sample split \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_sample_split = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators: 350\n",
      "Best depth: 3\n",
      "Best min sample split: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Best number of estimators:\", best_trees)\n",
    "print(\"Best depth:\", best_depth)\n",
    "print(\"Best min sample split:\", best_sample_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = best_depth, \n",
    "                                         min_samples_split = best_sample_split,\n",
    "                                         learning_rate = 0.1, loss = 'ls')\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(Xtest)\n",
    "y_predS = pd.Series(y_pred, index=NormInd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9324735407284117"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcv = linear_model.LassoCV(alphas=\n",
    "                           (10,11,12,13,14,15,16,), cv=5, max_iter=15000, normalize = True)\n",
    "lcv.fit(X_train, y_train)\n",
    "print (\"Alpha Value: \", (lcv.alpha_))\n",
    "lcv.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9332068873472752"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv = linear_model.RidgeCV(alphas=(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n",
    "                           cv=5)\n",
    "rcv.fit(X_train, y_train)\n",
    "print (\"Alpha Value: \", (rcv.alpha_))\n",
    "rcv.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  8\n"
     ]
    }
   ],
   "source": [
    "rcv = linear_model.RidgeCV(alphas=(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n",
    "                           cv=5)\n",
    "rcv.fit(X, y)\n",
    "print (\"Alpha Value: \", (rcv.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predR = rcv.predict(Xtest)\n",
    "y_predRS = pd.Series(y_predR, index=NormInd)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(cross_val_score(lcv, X, y, cv=5))  \n",
    "print(cross_val_score(rcv, X, y, cv=5))  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_predL = lasso.predict(X)\n",
    "lr_r2 =  r2_score(y, y_predL)\n",
    "print (\"R squared: \", (lr_r2))\n",
    "print (\"Average Coefficients: \", (abs(lasso.coef_).mean()))\n",
    "print (\"Root Mean Squared Error: \", sqrt(mean_squared_error(y, y_predL)))\n",
    "ax = sns.regplot(y, y_predL)\n",
    "plt.ylabel(\"Predicted Sale Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predL = lcv.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(Xout, yOut, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for trees 250 is: 0.866190970887135\n",
      "score for trees 300 is: 0.8587037838815303\n",
      "score for trees 350 is: 0.858681544319467\n",
      "score for trees 400 is: 0.8630746369126107\n",
      "score for trees 450 is: 0.8598427539293414\n",
      "score for trees 500 is: 0.8597404079054817\n"
     ]
    }
   ],
   "source": [
    "best_trees = 0\n",
    "score = 0\n",
    "for i in [250, 300, 350, 400, 450, 500]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = i, max_depth = 3, min_samples_split = 2,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for trees \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_trees = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for depth 2 is: 0.8723962248280464\n",
      "score for depth 3 is: 0.8597613280585542\n",
      "score for depth 4 is: 0.8198999125583875\n",
      "score for depth 5 is: 0.8362219754192045\n",
      "score for depth 6 is: 0.8460751751635959\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "score = 0\n",
    "for i in [2, 3, 4, 5, 6]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = i, min_samples_split = 2,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for depth \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_depth = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for min sample split 2 is: 0.8659851694145917\n",
      "score for min sample split 3 is: 0.8718053168498116\n",
      "score for min sample split 4 is: 0.8725249601852895\n",
      "score for min sample split 5 is: 0.864851713511851\n",
      "score for min sample split 6 is: 0.8721617153756607\n",
      "score for min sample split 7 is: 0.8684403878356588\n"
     ]
    }
   ],
   "source": [
    "best_sample_split = 0\n",
    "score = 0\n",
    "for i in [2, 3, 4, 5, 6, 7]:\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = best_depth, min_samples_split = i,\n",
    "                                             learning_rate = 0.1, loss = 'ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    temp = clf.score(X_val, y_val)\n",
    "    print(\"score for min sample split \" + str(i) +\" is: \" + str(temp))\n",
    "    if temp > score:\n",
    "        best_sample_split = i\n",
    "        score = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators: 250\n",
      "Best depth: 2\n",
      "Best min sample split: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Best number of estimators:\", best_trees)\n",
    "print(\"Best depth:\", best_depth)\n",
    "print(\"Best min sample split:\", best_sample_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=250, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingRegressor(n_estimators = best_trees, max_depth = best_depth, \n",
    "                                         min_samples_split = best_sample_split,\n",
    "                                         learning_rate = 0.1, loss = 'ls')\n",
    "clf.fit(Xout, yOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_out = clf.predict(XtestOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_outS = pd.Series(y_pred_out, index=OutInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paved Drive_N'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtestOut.columns[36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8220111587866262"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcv = linear_model.LassoCV(alphas=\n",
    "                           (10,11,12,13,14,15,16,), cv=5, max_iter=15000, normalize = True)\n",
    "lcv.fit(X_train, y_train)\n",
    "print (\"Alpha Value: \", (lcv.alpha_))\n",
    "lcv.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8267227494918039"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv = linear_model.RidgeCV(alphas=(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n",
    "                           cv=5)\n",
    "rcv.fit(X_train, y_train)\n",
    "print (\"Alpha Value: \", (rcv.alpha_))\n",
    "rcv.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Value:  10\n"
     ]
    }
   ],
   "source": [
    "rcv = linear_model.RidgeCV(alphas=(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n",
    "                           cv=5)\n",
    "rcv.fit(Xout, yOut)\n",
    "print (\"Alpha Value: \", (rcv.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predR_out = rcv.predict(XtestOut)\n",
    "y_predR_outS = pd.Series(y_predR_out, index=OutInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredCombOut = 1/2 * y_pred_outS + 1/2 * y_predR_outS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredComb = 1/2 * y_predS + 1/2 * y_predRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = yPredComb.append(yPredCombOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMIT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_comb = 1/2 * yPred + 1/2 * yPredR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = yPred\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
